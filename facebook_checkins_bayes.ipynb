{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path, os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import functools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "import argparse\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_k_precision(truthvalues, predictions):\n",
    "    z = (predictions == truthvalues[:, None]).astype(np.float32)\n",
    "    weights = 1./(np.arange(predictions.shape[1], dtype=np.float32) + 1.)\n",
    "    z = z * weights[None, :]\n",
    "    return float(np.mean(np.sum(z, axis=1)))\n",
    "\n",
    "\n",
    "\n",
    "def f_generator(dataframe):\n",
    "    mintue = dataframe['time'] % 60\n",
    "    dataframe['hour'] = dataframe['time'] // 60\n",
    "    dataframe['weekday'] = dataframe['hour'] // 24\n",
    "    dataframe['month'] = dataframe['weekday'] // 30\n",
    "    dataframe['year'] = (dataframe['weekday'] // 365 + 1)\n",
    "    dataframe['hour'] = ((dataframe['hour'] % 24 + 1) + mintue / 60.0)\n",
    "    dataframe['weekday'] = (dataframe['weekday'] % 7 + 1)\n",
    "    dataframe['month'] = (dataframe['month'] % 12 + 1)\n",
    "#     dataframe['log10acc'] = np.log10(dataframe['accuracy'].values)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def f_preprocessor(dataframe,\n",
    "                   w_x=500,\n",
    "                   w_y=1000,\n",
    "                   w_hour=4,\n",
    "#                    w_log10acc=15,\n",
    "                   w_weekday=3,\n",
    "                   w_month=2,\n",
    "                   w_year=8):\n",
    "    \n",
    "    dataframe[\"x\"] = dataframe[\"x\"] * w_x\n",
    "    dataframe[\"y\"] = dataframe[\"y\"] * w_y\n",
    "    dataframe[\"year\"] = dataframe[\"year\"] * w_year\n",
    "    dataframe[\"hour\"] = dataframe[\"hour\"] * w_hour\n",
    "    dataframe[\"weekday\"] = dataframe[\"weekday\"] * w_weekday\n",
    "    dataframe[\"month\"] = dataframe[\"month\"] * w_month\n",
    "#     dataframe['log10acc'] = np.log10(dataframe['accuracy'].values) * w_log10acc  \n",
    "    dataframe.drop(['time', 'accuracy'], axis=1, inplace=True)\n",
    "    return dataframe\n",
    "    \n",
    "\n",
    "def slicer_xy(df_train, df_test, slicer_param):\n",
    "    for param in slicer_param:\n",
    "        x_min, x_max, y_min, y_max = param[\"x_min\"], param[\"x_max\"], param[\"y_min\"], param[\"y_max\"]\n",
    "        x_border_augment, y_border_augment = param[\"x_border_augment\"], param[\"y_border_augment\"]\n",
    "        df_cell_train = df_train[(df_train['x'] >= x_min-x_border_augment)\n",
    "                         & (df_train['x'] < x_max+x_border_augment)\n",
    "                         & (df_train['y'] >= y_min-y_border_augment)\n",
    "                         & (df_train['y'] < y_max+y_border_augment)].copy()\n",
    "\n",
    "        df_cell_test = df_test[(df_test['x'] >= x_min)\n",
    "                           & (df_test['x'] < x_max)\n",
    "                           & (df_test['y'] >= y_min)\n",
    "                           & (df_test['y'] < y_max)].copy()\n",
    "\n",
    "        yield df_cell_train, df_cell_test\n",
    "    \n",
    "def slicer_param_generator_xy(**kwargs):\n",
    "    size = kwargs[\"size\"]\n",
    "    x_step = kwargs[\"x_step\"]\n",
    "    y_step = kwargs[\"y_step\"]\n",
    "    x_border_augment = x_step * 0.2\n",
    "    y_border_augment = y_step * 0.2\n",
    "    \n",
    "    cells = (int)(size/x_step)\n",
    "    for i in range(cells):\n",
    "        start_time_row = time.time()\n",
    "        x_min = x_step * i\n",
    "        x_max = x_step * (i+1)\n",
    "        x_min = round(x_min, 4)\n",
    "        x_max = round(x_max, 4)\n",
    "        if x_max == size:\n",
    "            x_max = x_max + 0.001\n",
    "\n",
    "        for j in range((int)(size/y_step)):\n",
    "            y_min = y_step * j\n",
    "            y_max = y_step * (j+1)\n",
    "            y_min = round(y_min, 4)\n",
    "            y_max = round(y_max, 4)\n",
    "            if y_max == size:\n",
    "                y_max = y_max + 0.001\n",
    "            yield {\"x_min\": x_min , \n",
    "                   \"x_max\" : x_max,\n",
    "                   \"y_min\" : y_min,\n",
    "                   \"y_max\" : y_max,\n",
    "                   \"x_border_augment\": x_border_augment,\n",
    "                   \"y_border_augment\": y_border_augment}\n",
    "\n",
    "def do_predict(df_cell_train, df_cell_test, th, n_neighbors):\n",
    "\n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = (place_counts[df_cell_train.place_id.values] >= th).values\n",
    "    df_cell_train = df_cell_train.loc[mask]\n",
    "    \n",
    "    row_ids = df_cell_test.index\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_cell_train.place_id.values)\n",
    "    X = df_cell_train.drop(['place_id'], axis=1).values.astype(float)\n",
    "\n",
    "    X_test = df_cell_test.values.astype(float)\n",
    "\n",
    "    # Applying the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=int(n_neighbors),\n",
    "                               weights='distance',\n",
    "                               metric='manhattan')\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    pred_labels = le.inverse_transform(\n",
    "        np.argsort(y_pred, axis=1)[:, ::-1][:, :3])\n",
    "    return pred_labels, row_ids\n",
    "\n",
    "\n",
    "def ml_pipeline(slicer, th=5, n_neighbors=26):\n",
    "    for cell_train, cell_test in slicer:\n",
    "        pred_labels, row_id = do_predict(f_preprocessor(cell_train),\n",
    "                                         f_preprocessor(cell_test),\n",
    "                                         th, n_neighbors)\n",
    "        yield pred_labels, row_id\n",
    "\n",
    "\n",
    "def wraper_for_optimization():\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n"
     ]
    }
   ],
   "source": [
    "now_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "\n",
    "print('Loading data ...')\n",
    "df_train = pd.read_csv('/opt/devs/train_facebook.csv',\n",
    "                       usecols=[\n",
    "                           'row_id', 'x', 'y', 'accuracy', 'time', 'place_id'],\n",
    "                       index_col=0, nrows=100000)\n",
    "df_train.sort_values('time', inplace=True)\n",
    "df_test = pd.read_csv('/opt/devs/test_facebook.csv',\n",
    "                      usecols=['row_id', 'x', 'y', 'accuracy', 'time'],\n",
    "                      index_col=0, nrows=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {\"size\": 10, \"x_step\": 1.0, \"y_step\" : 0.5}\n",
    "th = 5 \n",
    "n_neighbors = 10\n",
    "output_path = \"/opt/devs/facebook_eugene.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature generation\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = f_generator(df_train)\n",
    "df_test = f_generator(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ninety_percent_mark = int(df_train.shape[0]*0.7)\n",
    "\n",
    "df_validation_test = df_train[ninety_percent_mark:]\n",
    "truthvalues = df_validation_test.place_id.values\n",
    "\n",
    "df_validation_test.drop([\"place_id\"], axis=1, inplace=True)\n",
    "\n",
    "df_test2 = df_validation_test.copy()\n",
    "df_test2['pred1'] = -99\n",
    "df_test2['pred2'] = -99\n",
    "df_test2['pred3'] = -99\n",
    "df_test2.drop([column for column in df_test2.columns if \"pred\" not in column], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_validation_train = df_train[:ninety_percent_mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slicer_param_gen = slicer_param_generator_xy(**param)\n",
    "slicer_gen = slicer_xy(df_validation_train, df_validation_test, slicer_param_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = ml_pipeline(slicer_gen, n_neighbors=n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4131955276, 5272614689], dtype=int64)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2) into shape (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-243-6286bc861a68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_ids\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mdf_test2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;31m# actually do the set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   2841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2843\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'setitem'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   2821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2822\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2823\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2824\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, indexer, value, mgr)\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# GH 6043\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0m_is_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m                 \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[1;31m# if we are an exact match (ex-broadcasting),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (2) into shape (3)"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for pred_labels, row_ids in pipeline:\n",
    "    for ids, labs in zip(row_ids, pred_labels):\n",
    "        df_test2.loc[ids] = np.array(labs)\n",
    "    if cnt % 10 == 0:\n",
    "        print(cnt)\n",
    "        cnt+=1\n",
    "        \n",
    "predictions = df_test2[['pred1', 'pred2', 'pred3']].as_matrix()\n",
    "mapk = map_k_precision(truthvalues, predictions)\n",
    "print(mapk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate submission\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slicer_param_gen = slicer_param_generator_xy(**param)\n",
    "slicer_gen = slicer_xy(df_validation_train, df_validation_test, slicer_param_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = ml_pipeline(slicer_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(output_path) as f:\n",
    "    f.write('row_id,place_id\\n')\n",
    "    for pred_labels, row_ids in pipeline:\n",
    "        for ids, labs in zip(row_ids, pred_labels):\n",
    "            fh.write(\"{0},{1}\\n\".format(ids, ' '.join([str(x) for x in labs])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
