{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path, os\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import functools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "import argparse\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALIDATION = True\n",
    "BAYESIAN_OPTIMIZATION = False\n",
    "\n",
    "size = 10.\n",
    "x_step = 1.0\n",
    "y_step = 0.5\n",
    "x_border_augment = x_step * 0.2\n",
    "y_border_augment = y_step * 0.2\n",
    "n_neighbors = 10\n",
    "uuid_string = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-81-d1ede5abd6e3>, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-81-d1ede5abd6e3>\"\u001b[1;36m, line \u001b[1;32m50\u001b[0m\n\u001b[1;33m    if tp=\"xy\":\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def map_k_precision(truthvalues, predictions):\n",
    "    z = (predictions == truthvalues[:, None]).astype(np.float32)\n",
    "    weights = 1./(np.arange(predictions.shape[1], dtype=np.float32) + 1.)\n",
    "    z = z * weights[None, :]\n",
    "    return float(np.mean(np.sum(z, axis=1)))\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(dataframe,\n",
    "                 w_hour=None,\n",
    "                 w_log10acc=None,\n",
    "                 w_weekday=None,\n",
    "                 w_month=None,\n",
    "                 w_year=None,):\n",
    "    mintue = dataframe['time'] % 60\n",
    "    dataframe['hour'] = dataframe['time'] // 60\n",
    "    dataframe['weekday'] = dataframe['hour'] // 24\n",
    "    dataframe['month'] = dataframe['weekday'] // 30\n",
    "    dataframe['year'] = (dataframe['weekday'] // 365 + 1) * w_year\n",
    "    dataframe['hour'] = ((dataframe['hour'] % 24 + 1) + mintue / 60.0) * w_hour\n",
    "    dataframe['weekday'] = (dataframe['weekday'] % 7 + 1) * w_weekday\n",
    "    dataframe['month'] = (dataframe['month'] % 12 + 1) * w_month\n",
    "    dataframe['log10acc'] = np.log10(dataframe['accuracy'].values) * w_log10acc\n",
    "    dataframe.drop(['time', 'accuracy'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def slicer(df_train, df_test, tp=\"xy\", *kwargs):\n",
    "    if tp == \"xy\":\n",
    "        x_min, x_max, y_min, y_max = kwargs[\"x_min\"], kwargs[\"x_max\"], kwargs[\"y_min\"], kwargs[\"y_max\"]\n",
    "        x_border_augment, y_border_augment = kwargs[\"x_border_augment\"], kwargs[\"y_border_augment\"]\n",
    "        df_cell_train = df_train[(df_train['x'] >= x_min-x_border_augment)\n",
    "                         & (df_train['x'] < x_max+x_border_augment)\n",
    "                         & (df_train['y'] >= y_min-y_border_augment)\n",
    "                         & (df_train['y'] < y_max+y_border_augment)].copy()\n",
    "        \n",
    "        df_cell_test = df_test[(df_test['x'] >= x_min)\n",
    "                           & (df_test['x'] < x_max)\n",
    "                           & (df_test['y'] >= y_min)\n",
    "                           & (df_test['y'] < y_max)].copy()\n",
    "        \n",
    "        return df_cell_train, df_cell_test\n",
    "    \n",
    "    elif tp == \"hour\":\n",
    "        pass\n",
    "\n",
    "    \n",
    "def slicer_param_generator(tp=\"xy\", **kwargs):\n",
    "    if tp=\"xy\":\n",
    "        size = kwargs[\"size\"]\n",
    "        x_step = kwargs[\"x_step\"]\n",
    "        y_step = kwargs[\"y_step\"]\n",
    "        cells = (int)(size/x_step)\n",
    "        for i in range(cells):\n",
    "            start_time_row = time.time()\n",
    "            x_min = x_step * i\n",
    "            x_max = x_step * (i+1)\n",
    "            x_min = round(x_min, 4)\n",
    "            x_max = round(x_max, 4)\n",
    "            if x_max == size:\n",
    "                x_max = x_max + 0.001\n",
    "\n",
    "            for j in range((int)(size/y_step)):\n",
    "                y_min = y_step * j\n",
    "                y_max = y_step * (j+1)\n",
    "                y_min = round(y_min, 4)\n",
    "                y_max = round(y_max, 4)\n",
    "                if y_max == size:\n",
    "                    y_max = y_max + 0.001\n",
    "                yield {\"x_min\": x_min , \"x_max\" : x_max, \"y_min\" : y_min, \"y_max\" : y_max}\n",
    "    elif tp == \"\":\n",
    "        pass\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "def process_one_cell(df_cell_train, df_cell_test, **kwargs,\n",
    "                     th=None,\n",
    "                     w_x=None,\n",
    "                     w_y=None,\n",
    "                     w_hour=None,\n",
    "                     w_log10acc=None,\n",
    "                     w_weekday=None,\n",
    "                     w_month=None,\n",
    "                     w_year=None,\n",
    "                     n_neighbors=None):\n",
    "\n",
    "    # Working on df_train\n",
    "    \n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = (place_counts[df_cell_train.place_id.values] >= th).values\n",
    "    \n",
    "    df_cell_train = df_cell_train.loc[mask]\n",
    "    df_cell_train = prepare_data(df_cell_train, \n",
    "                                 w_hour=w_hour,\n",
    "                                 w_log10acc=w_log10acc,\n",
    "                                 w_weekday=w_weekday,\n",
    "                                 w_month=w_month,\n",
    "                                 w_year=w_year,)\n",
    "\n",
    "    # Working on df_test\n",
    "\n",
    "    row_ids = df_cell_test.index\n",
    "\n",
    "    # Feature engineering on x and y\n",
    "    df_cell_train.loc[:, 'x'] *= w_x\n",
    "    df_cell_train.loc[:, 'y'] *= w_y\n",
    "    df_cell_test.loc[:, 'x'] *= w_x\n",
    "    df_cell_test.loc[:, 'y'] *= w_y\n",
    "    df_cell_test = prepare_data(df_cell_test, \n",
    "                                w_hour=w_hour,\n",
    "                                w_log10acc=w_log10acc,\n",
    "                                w_weekday=w_weekday,\n",
    "                                w_month=w_month,\n",
    "                                w_year=w_year,)\n",
    "\n",
    "    # Preparing data\n",
    "\n",
    "\n",
    "    return pred_labels, row_ids\n",
    "\n",
    "def do_predict(df_cell_train, df_cell_test):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_cell_train.place_id.values)\n",
    "    X = df_cell_train.drop(['place_id'], axis=1).values.astype(float)\n",
    "\n",
    "    X_test = df_cell_test.values.astype(float)\n",
    "\n",
    "    # Applying the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=int(round(n_neighbors)),\n",
    "                               weights='distance',\n",
    "                               metric='manhattan')\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    pred_labels = le.inverse_transform(\n",
    "        np.argsort(y_pred, axis=1)[:, ::-1][:, :3])\n",
    "\n",
    "\n",
    "def process_grid(slicer, processor, do_predict \n",
    "                 # INITIAL GUESS PARAMS\n",
    "#                   th=5,\n",
    "#                   w_x=500,\n",
    "#                   w_y=1000,\n",
    "#                   w_hour=4,\n",
    "#                   w_log10acc=15,\n",
    "#                   w_weekday=3,\n",
    "#                   w_month=2,\n",
    "#                   w_year=10,\n",
    "#                   n_neighbors=25\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Iterates over all grid cells, aggregates the results and makes the\n",
    "    submission.\n",
    "    \"\"\"\n",
    "\n",
    "#     if VALIDATION:\n",
    "#         df_test2 = df_test.copy()\n",
    "#         truthvalues = df_test2.place_id.values\n",
    "#         df_test2['pred1'] = -99\n",
    "#         df_test2['pred2'] = -99\n",
    "#         df_test2['pred3'] = -99\n",
    "\n",
    "#         df_test2.drop(['x', 'y', 'accuracy', 'time'], axis=1, inplace=True)\n",
    "\n",
    "   \n",
    "    for cell_train, cell_test in slicer:\n",
    "        # Applying classifier to one grid cell\n",
    "            pred_labels, row_ids = processor(cell_train, cell_test)\n",
    "            for i_d, labs in zip(row_ids, pred_labels):\n",
    "                if VALIDATION and (not write_validation):\n",
    "                    df_test2.loc[i_d].values[1:] = np.array(labs)\n",
    "                else:\n",
    "                    fh.write(\"{0},{1}\\n\".format(\n",
    "                        i_d, ' '.join([str(x) for x in labs]))\n",
    "                    )\n",
    "        print(\"STAGE={0} FROM={1}\".format(*[i, cells]))\n",
    "    if VALIDATION:\n",
    "        truthvalues = [[i] for i in df_test2.place_id.values]\n",
    "        predictions = list(df_test2[['pred1', 'pred2', 'pred3']].values)\n",
    "\n",
    "        #truthvalues = truthvalues[predictions[:, 0] != -99]\n",
    "        #predictions = predictions[predictions[:, 0] != -99]\n",
    "\n",
    "        return mapk(truthvalues, predictions, 3)\n",
    "\n",
    "def wraper_for_optimization():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "\n",
    "print('Loading data ...')\n",
    "df_train = pd.read_csv('/opt/devs/train_facebook.csv',\n",
    "                       usecols=[\n",
    "                           'row_id', 'x', 'y', 'accuracy', 'time', 'place_id'],\n",
    "                       index_col=0)\n",
    "df_train.sort_values('time', inplace=True)\n",
    "df_test = pd.read_csv('/opt/devs/test_facebook.csv',\n",
    "                      usecols=['row_id', 'x', 'y', 'accuracy', 'time'],\n",
    "                      index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Validation Mode. Taking last 10% of training as test set.\n",
      "STAGE=0 FROM=10\n",
      "STAGE=1 FROM=10\n",
      "STAGE=2 FROM=10\n",
      "STAGE=3 FROM=10\n",
      "STAGE=4 FROM=10\n",
      "STAGE=5 FROM=10\n",
      "STAGE=6 FROM=10\n",
      "STAGE=7 FROM=10\n",
      "STAGE=8 FROM=10\n",
      "STAGE=9 FROM=10\n",
      "SCORE=0.0\n"
     ]
    }
   ],
   "source": [
    "if BAYESIAN_OPTIMIZATION:\n",
    "    print(\n",
    "        \"Bayesian Optimization mode. Taking last 10% of training as test set.\")\n",
    "    ninety_percent_mark = int(df_train.shape[0]*0.9)\n",
    "    df_test = df_train[ninety_percent_mark:]\n",
    "    df_train = df_train[:ninety_percent_mark]\n",
    "\n",
    "    f = functools.partial(process_grid, df_train=df_train, df_test=df_test,\n",
    "                          outfilename=outfilename, n_neighbors=n_neighbors)\n",
    "    \n",
    "    bo = BayesianOptimization(f=f,\n",
    "                              pbounds={\n",
    "                                  'th': (0, 4.1),\n",
    "                                  'w_x': (100, 1000),\n",
    "                                  # Fix w_y at 1000 as the most important feature\n",
    "                                  #'w_y': (500, 2000), \n",
    "                                  \"w_hour\": (1, 10),\n",
    "                                  \"w_log10acc\": (3, 30),\n",
    "                                  \"w_weekday\": (1, 10),\n",
    "                                  \"w_month\": (1, 10),\n",
    "                                  \"w_year\": (2, 20),\n",
    "                                  \"n_neighbors\": (1, 30)},\n",
    "                              verbose=True\n",
    "                              )\n",
    "\n",
    "\n",
    "    bo.maximize(init_points=2, n_iter=1, acq=\"ei\", xi=0.1)\n",
    "    with open('knn_params/{}.json'.format(uuid_string), 'w') as fh:\n",
    "        fh.write(json.dumps(bo.res, sort_keys=True, indent=4))\n",
    "\n",
    "    for i in range(300):\n",
    "        bo.maximize(n_iter=1, acq=\"ei\", xi=0.0) # exploration points\n",
    "        with open('knn_params/{}.json'.format(uuid_string), 'w') as fh:\n",
    "            fh.write(json.dumps(bo.res, sort_keys=True, indent=4))\n",
    "\n",
    "        bo.maximize(n_iter=1, acq=\"ei\", xi=0.1) # exploitation points\n",
    "        with open('knn_params/{}.json'.format(uuid_string), 'w') as fh:\n",
    "            fh.write(json.dumps(bo.res, sort_keys=True, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "elif VALIDATION:\n",
    "    print(\"Validation Mode. Taking last 10% of training as test set.\")\n",
    "    ninety_percent_mark = int(df_train.shape[0]*0.8)\n",
    "    df_test = df_train[ninety_percent_mark:]\n",
    "    df_train = df_train[:ninety_percent_mark]\n",
    "    outfilename = sub_file = os.path.join(\n",
    "        'vali_{0}.csv'.format(str(now_time)))\n",
    "    validation = process_grid(df_train, df_test, outfilename, write_validation=True)\n",
    "    print(\"SCORE=\" + str(validation))\n",
    "    \n",
    "else:\n",
    "    print(\"Normal Mode. Generating test set predictions.\")\n",
    "    outfilename = sub_file = os.path.join(\n",
    "        'pred_{0}.csv'.format(str(now_time)))\n",
    "    process_grid(df_train, df_test, outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def a(t1, t2, **kwargs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
